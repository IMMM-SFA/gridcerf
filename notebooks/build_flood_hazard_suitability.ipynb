{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b38332",
   "metadata": {},
   "source": [
    "# Build flood hazard suitablity layers for GRIDCERF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5099ca6a-143f-430a-96c3-6c1f3feefc56",
   "metadata": {},
   "source": [
    "The following code was used to build the flood hazard suitability layers for GRIDCERF. GRIDCERF does not provide the source data directly due to some license restrictions related for direct redistribution of the unaltered source data.  However, the following details the provenance associated with each source dataset and how they were processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487305fe",
   "metadata": {},
   "source": [
    "## 1. Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c00a6-80ac-45d4-85cd-84d33530a59f",
   "metadata": {},
   "source": [
    "### 1.1 Download GRIDCERF\n",
    "\n",
    "Download the GRIDCERF package if you have not yet done so from here:  https://doi.org/10.57931/2281697.  Please extract GRIDCERF inside the `data` directory of this repository as the paths in this notebook are set to that expectation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264dd049",
   "metadata": {},
   "source": [
    "### 1.2 Data description\n",
    "\n",
    "- **Title**: FEMA National Flood Hazard Layer\n",
    "- **Description from Source**: The National Flood Hazard Layer (NFHL) is a geospatial database that contains current effective flood hazard data. FEMA provides the flood hazard data to support the National Flood Insurance Program. You can use the information to better understand your level of flood risk and type of flooding.\n",
    "- **Source URL**:  https://msc.fema.gov/portal/advanceSearch\n",
    "- **Date Accessed**:  03/23/23\n",
    "- **Citation**\n",
    "> US Federal Emergency Management Agency, 2023. FEMA National Flood Hazard Layer. https://msc.fema.gov/portal/advanceSearch\n",
    "- **Application**: US FEMA provides flood risk data for regions where they have conducted detailed or approximate studies. They provide flood risk assessment information that are categorized by the following types:\n",
    "\n",
    "    * A: 1-percent annual chance flood event (a.k.a, base flood or 100-year flood) using approximate methodologies, no detailed hydraulic analyses have been performed.\n",
    "    * AE: 1-percent annual chance flood event determined through detailed hydraulic analyses.\n",
    "    * A99: Areas with a 1% annual chance of flooding that will be protected by a Federal flood control system.\n",
    "    * AH: Areas with a 1% annual chance of shallow flooding, usually in the form of a pond, with an average depth ranging from 1 to 3 feet\n",
    "    * AO: River or stream flood hazard areas, and areas with a 1% or greater chance of shallow flooding each year, usually in the form of sheet flow, with an average depth ranging from 1 to 3 feet.\n",
    "    * V or VE: Coastal areas with a 1% or greater chance of flooding and an additional hazard associated with storm waves.\n",
    "    * X: outside the 500-year flood and protected by levee from 100- year flood\n",
    "    * D: undetermined flood hazards\n",
    "State level data is directly downloadable at the FEMA flood hazard website, here: https://msc.fema.gov/portal/advanceSearch. To access the appropriate state-level file select a state, then a county, then a community (doesn't matter which county or community), then hit search, then click \"effective products\", then NFHL Data-State, then download\n",
    "\n",
    "For the GRIDCERF flood hazard exclusion layers, the following risk categories are used to create separate suitability: A/AE and V/VE. This notebook assumes that the A/AE and V/VE data has been separately downloaded for each state individually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d63a3a",
   "metadata": {},
   "source": [
    "### 1.3 Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "794af5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio import features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed6f1a",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e95543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parent directory path to where this notebook is currently stored\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# data directory in repository\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "\n",
    "# GRIDCERF data directory from downloaded archive absolute path\n",
    "gridcerf_dir = os.path.join(data_dir, \"gridcerf\")\n",
    "\n",
    "# GRIDCERF local technology-specific data directory\n",
    "technology_specific_dir = os.path.join(gridcerf_dir, 'technology_specific')\n",
    "\n",
    "# GRIDCERF local common data directory\n",
    "common_dir = os.path.join(gridcerf_dir, 'common')\n",
    "\n",
    "# GRIDCERF reference data directory\n",
    "reference_dir = os.path.join(gridcerf_dir, 'reference')\n",
    "\n",
    "# GRIDCERF compiled final suitability data directory\n",
    "compiled_dir = os.path.join(gridcerf_dir, \"compiled\")\n",
    "\n",
    "# template land mask raster\n",
    "template_raster = os.path.join(reference_dir, \"gridcerf_sitingmask.tif\")\n",
    "\n",
    "# template ocean mask raster\n",
    "ocean_template_raster = os.path.join(reference_dir, \"gridcerf_oceanmask.tif\")\n",
    "\n",
    "# source data directory\n",
    "source_dir = os.path.join(gridcerf_dir,  \"source\", 'technology_specific', 'flood_hazard_zones')\n",
    "\n",
    "# V-VE source data file\n",
    "vve_source_file = os.path.join(source_dir, \"usfema_zone_v-ve_shp\", \"V-VE.shp\")\n",
    "\n",
    "# share drive directory\n",
    "aae_dir = os.path.join(source_dir, \"usfema_zone_a-ae_shp\")\n",
    "\n",
    "# temporary output raster for processing\n",
    "temp_output_raster = os.path.join(source_dir, \"temporary_raster.tif\")\n",
    "\n",
    "# temporary outpust shapefile for processing\n",
    "temp_output_shp = os.path.join(source_dir, \"gridcerf_flood_risk_shp\" ,\"temporary_shp.shp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e519fd",
   "metadata": {},
   "source": [
    "## 3. Generate Raster(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9121ca7",
   "metadata": {},
   "source": [
    "### 3.1 Functions to build files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf51491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_coastal_flood_shp_file(source_file = vve_source_file):\n",
    "    \"\"\" \n",
    "    Process shapefile and prepare a rasterization field.\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(source_file)\n",
    "    \n",
    "    # dissolve into single polygon\n",
    "    gdf['value'] = 1\n",
    "    gdf = gdf.dissolve(by=\"value\", as_index=False)\n",
    "    \n",
    "    # reproject shapefile\n",
    "    gdf.to_crs(\"ESRI:102003\", inplace=True)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def process_state_inland_floor_shp_file(source_file):\n",
    "    \n",
    "    gdf = gpd.read_file(source_file)\n",
    "    \n",
    "    # reproject shapefile\n",
    "    gdf.to_crs(\"ESRI:102003\", inplace=True)\n",
    "    \n",
    "    # set initial value to zero for state-wise matrix multiplication\n",
    "    gdf['value'] = 0\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def combine_state_inland_flood_risk_data(flood_dir = aae_dir):\n",
    "    \"\"\" Iterates through all state-level flood risk shapefiles, reprojects them, rasterizes them, and \n",
    "    combines the rasters into one CONUS raster\"\"\"\n",
    "\n",
    "    file_list =[]\n",
    "    # loop through shapefile directory\n",
    "    for file in os.listdir(flood_dir):\n",
    "        if file.endswith('shp'):\n",
    "        \n",
    "            print(f'Processing {file}...')\n",
    "        \n",
    "            file_list.append(file)\n",
    "            index = file_list.index(file)\n",
    "        \n",
    "            file_path = os.path.join(aae_dir, file)\n",
    "        \n",
    "            # read in and process state-level shapefile\n",
    "            gdf = process_state_inland_floor_shp_file(file_path)\n",
    "        \n",
    "            print(f'Saving {file} to shp...')\n",
    "            # save state_level file to temp shapefile\n",
    "            gdf.to_file(temp_output_shp)\n",
    "        \n",
    "            print(f'Rasterizing {file}...')\n",
    "            # set paths for temporary rasterization\n",
    "            output_shp = os.path.join(source_dir,\"gridcerf_flood_risk_shp\", \"temporary_shp.shp\")\n",
    "            output_raster = os.path.join(source_dir, \"gridcerf_flood_risk_shp\", \"temporary_raster.tif\")\n",
    "        \n",
    "            # construct the GDAL raster command\n",
    "            gdal_rasterize_cmd = f\"gdal_rasterize -a value -tr 1000.0 1000.0 -init 1 -te -2831615.228 -1539013.3223 2628318.0948 1690434.1707 -ot Int16 -of GTiff {output_shp} {output_raster}\"\n",
    "\n",
    "            # execute the GDAL command via the system terminal\n",
    "            os.system(gdal_rasterize_cmd)\n",
    "        \n",
    "            # read in temp raster with rasterio\n",
    "            full_temp_raster_path = os.path.join(source_dir,\"gridcerf_flood_risk_shp\", \"temporary_raster.tif\")\n",
    "            \n",
    "            temporary_flood_raster = rasterio.open(full_temp_raster_path)\n",
    "            flood_array = temporary_flood_raster.read(1)\n",
    "        \n",
    "            # cross multiply with the merged set\n",
    "            if index == 0:\n",
    "                combined_raster = flood_array\n",
    "            else:\n",
    "                combined_raster = combined_raster*flood_array\n",
    "\n",
    "    combined_raster *= template_raster\n",
    "\n",
    "    return combined_raster\n",
    "\n",
    "def vector_to_raster(template_raster, land_mask_raster, gdf, value_field, output_raster, include):\n",
    "                     \n",
    "    # open the template raster and extract metadata and land mask\n",
    "    with rasterio.open(template_raster) as template:\n",
    "\n",
    "        metadata = template.meta.copy()\n",
    "\n",
    "        # update raster data type\n",
    "        metadata.update(dtype=np.int16)\n",
    "\n",
    "        # extract land mask\n",
    "        land_mask_file = rasterio.open(land_mask_raster)\n",
    "        land_mask = land_mask_file.read(1)\n",
    "        land_mask = np.where(land_mask == 0, np.nan, 1)\n",
    "\n",
    "        # write output raster\n",
    "        with rasterio.open(output_raster, 'w+', **metadata) as out:\n",
    "\n",
    "            out_arr = out.read(1)\n",
    "\n",
    "            # build shapes to rasterize from target geometry and field\n",
    "            shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[value_field]))\n",
    "\n",
    "            # burn features\n",
    "            burned = features.rasterize(shapes=shapes, \n",
    "                                        fill=0, \n",
    "                                        out=out_arr, \n",
    "                                        transform=out.transform)\n",
    "            \n",
    "            burned = np.where(burned == 1, 1, 0).astype(np.float64)\n",
    "\n",
    "            # invert suitability for inclusion layer\n",
    "            if include:\n",
    "                burned = np.where(burned==1, 0, 1).astype(np.float64)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # apply land mask\n",
    "            burned *= land_mask\n",
    "            \n",
    "            # make nan excluded\n",
    "            burned = np.where(np.isnan(burned), 1, burned)\n",
    "\n",
    "            out.write_band(1, burned.astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3cb24d",
   "metadata": {},
   "source": [
    "### 3.2 Generate shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2bc1c3",
   "metadata": {},
   "source": [
    "#### Coastal flood risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38049dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing shapefile data...\n",
      "Preprocessing complete\n",
      "CPU times: user 3min 11s, sys: 8.66 s, total: 3min 19s\n",
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# preprocess shapefile\n",
    "print(\"Preprocessing shapefile data...\")\n",
    "gdf = process_coastal_flood_shp_file()\n",
    "\n",
    "# construct temporary shapefile output file path\n",
    "coastal_output_shp_file_name = \"gridcerf_fema_1pct_or_greater_coastal_flood_risk.shp\"\n",
    "output_shp = os.path.join(source_dir, \"gridcerf_flood_risk_shp\", coastal_output_shp_file_name)\n",
    "\n",
    "# write output shapefile\n",
    "gdf.to_file(output_shp)\n",
    "print('Preprocessing complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22076d95",
   "metadata": {},
   "source": [
    "### 3.3 Generate rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1121be",
   "metadata": {},
   "source": [
    "#### 100-year inland flood risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d8e9bd-af74-44d8-a833-ed690b682595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the template raster\n",
    "template_raster = rasterio.open(template_raster).read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c29b382b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing shapefile data...\n",
      "Processing NFHL_12_20230302.shp...\n",
      "Saving NFHL_12_20230302.shp to shp...\n",
      "Rasterizing NFHL_12_20230302.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_31_20221026.shp...\n",
      "Saving NFHL_31_20221026.shp to shp...\n",
      "Rasterizing NFHL_31_20221026.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_55_20230302.shp...\n",
      "Saving NFHL_55_20230302.shp to shp...\n",
      "Rasterizing NFHL_55_20230302.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_33_20221013.shp...\n",
      "Saving NFHL_33_20221013.shp to shp...\n",
      "Rasterizing NFHL_33_20221013.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_02_20220910.shp...\n",
      "Saving NFHL_02_20220910.shp to shp...\n",
      "Rasterizing NFHL_02_20220910.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_34_20230122.shp...\n",
      "Saving NFHL_34_20230122.shp to shp...\n",
      "Rasterizing NFHL_34_20230122.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_06_20230303.shp...\n",
      "Saving NFHL_06_20230303.shp to shp...\n",
      "Rasterizing NFHL_06_20230303.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_37_20230303.shp...\n",
      "Saving NFHL_37_20230303.shp to shp...\n",
      "Rasterizing NFHL_37_20230303.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_53_20220926.shp...\n",
      "Saving NFHL_53_20220926.shp to shp...\n",
      "Rasterizing NFHL_53_20220926.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_09_20221113.shp...\n",
      "Saving NFHL_09_20221113.shp to shp...\n",
      "Rasterizing NFHL_09_20221113.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_13_20230301.shp...\n",
      "Saving NFHL_13_20230301.shp to shp...\n",
      "Rasterizing NFHL_13_20230301.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_49_20230221.shp...\n",
      "Saving NFHL_49_20230221.shp to shp...\n",
      "Rasterizing NFHL_49_20230221.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_04_20230208.shp...\n",
      "Saving NFHL_04_20230208.shp to shp...\n",
      "Rasterizing NFHL_04_20230208.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_24_20230203.shp...\n",
      "Saving NFHL_24_20230203.shp to shp...\n",
      "Rasterizing NFHL_24_20230203.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_50_20211216.shp...\n",
      "Saving NFHL_50_20211216.shp to shp...\n",
      "Rasterizing NFHL_50_20211216.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_66_20070928.shp...\n",
      "Saving NFHL_66_20070928.shp to shp...\n",
      "Rasterizing NFHL_66_20070928.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_56_20221104.shp...\n",
      "Saving NFHL_56_20221104.shp to shp...\n",
      "Rasterizing NFHL_56_20221104.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_05_20230218.shp...\n",
      "Saving NFHL_05_20230218.shp to shp...\n",
      "Rasterizing NFHL_05_20230218.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_38_20230119.shp...\n",
      "Saving NFHL_38_20230119.shp to shp...\n",
      "Rasterizing NFHL_38_20230119.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_17_20230218.shp...\n",
      "Saving NFHL_17_20230218.shp to shp...\n",
      "Rasterizing NFHL_17_20230218.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_45_20230218.shp...\n",
      "Saving NFHL_45_20230218.shp to shp...\n",
      "Rasterizing NFHL_45_20230218.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_69_20060403.shp...\n",
      "Saving NFHL_69_20060403.shp to shp...\n",
      "Rasterizing NFHL_69_20060403.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_20_20221116.shp...\n",
      "Saving NFHL_20_20221116.shp to shp...\n",
      "Rasterizing NFHL_20_20221116.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_27_20230225.shp...\n",
      "Saving NFHL_27_20230225.shp to shp...\n",
      "Rasterizing NFHL_27_20230225.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_30_20221124.shp...\n",
      "Saving NFHL_30_20221124.shp to shp...\n",
      "Rasterizing NFHL_30_20221124.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_11_20211216.shp...\n",
      "Saving NFHL_11_20211216.shp to shp...\n",
      "Rasterizing NFHL_11_20211216.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_26_20230222.shp...\n",
      "Saving NFHL_26_20230222.shp to shp...\n",
      "Rasterizing NFHL_26_20230222.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_36_20230204.shp...\n",
      "Saving NFHL_36_20230204.shp to shp...\n",
      "Rasterizing NFHL_36_20230204.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_78_20160630.shp...\n",
      "Saving NFHL_78_20160630.shp to shp...\n",
      "Rasterizing NFHL_78_20160630.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_54_20230228.shp...\n",
      "Saving NFHL_54_20230228.shp to shp...\n",
      "Rasterizing NFHL_54_20230228.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_18_20230303.shp...\n",
      "Saving NFHL_18_20230303.shp to shp...\n",
      "Rasterizing NFHL_18_20230303.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_46_20220831.shp...\n",
      "Saving NFHL_46_20220831.shp to shp...\n",
      "Rasterizing NFHL_46_20220831.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_25_20230228.shp...\n",
      "Saving NFHL_25_20230228.shp to shp...\n",
      "Rasterizing NFHL_25_20230228.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_01_20230217.shp...\n",
      "Saving NFHL_01_20230217.shp to shp...\n",
      "Rasterizing NFHL_01_20230217.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_10_20230222.shp...\n",
      "Saving NFHL_10_20230222.shp to shp...\n",
      "Rasterizing NFHL_10_20230222.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_72_20211216.shp...\n",
      "Saving NFHL_72_20211216.shp to shp...\n",
      "Rasterizing NFHL_72_20211216.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_41_20230227.shp...\n",
      "Saving NFHL_41_20230227.shp to shp...\n",
      "Rasterizing NFHL_41_20230227.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_35_20230217.shp...\n",
      "Saving NFHL_35_20230217.shp to shp...\n",
      "Rasterizing NFHL_35_20230217.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_16_20230228.shp...\n",
      "Saving NFHL_16_20230228.shp to shp...\n",
      "Rasterizing NFHL_16_20230228.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_39_20230302.shp...\n",
      "Saving NFHL_39_20230302.shp to shp...\n",
      "Rasterizing NFHL_39_20230302.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_48_20230301.shp...\n",
      "Saving NFHL_48_20230301.shp to shp...\n",
      "Rasterizing NFHL_48_20230301.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_08_20230303.shp...\n",
      "Saving NFHL_08_20230303.shp to shp...\n",
      "Rasterizing NFHL_08_20230303.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_32_20230215.shp...\n",
      "Saving NFHL_32_20230215.shp to shp...\n",
      "Rasterizing NFHL_32_20230215.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_60_20060717.shp...\n",
      "Saving NFHL_60_20060717.shp to shp...\n",
      "Rasterizing NFHL_60_20060717.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_42_20230215.shp...\n",
      "Saving NFHL_42_20230215.shp to shp...\n",
      "Rasterizing NFHL_42_20230215.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_29_20220130.shp...\n",
      "Saving NFHL_29_20220130.shp to shp...\n",
      "Rasterizing NFHL_29_20220130.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_21_20221130.shp...\n",
      "Saving NFHL_21_20221130.shp to shp...\n",
      "Rasterizing NFHL_21_20221130.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_22_20230223.shp...\n",
      "Saving NFHL_22_20230223.shp to shp...\n",
      "Rasterizing NFHL_22_20230223.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_19_20221214.shp...\n",
      "Saving NFHL_19_20221214.shp to shp...\n",
      "Rasterizing NFHL_19_20221214.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_23_20211216.shp...\n",
      "Saving NFHL_23_20211216.shp to shp...\n",
      "Rasterizing NFHL_23_20211216.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_40_20230218.shp...\n",
      "Saving NFHL_40_20230218.shp to shp...\n",
      "Rasterizing NFHL_40_20230218.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_51_20230303.shp...\n",
      "Saving NFHL_51_20230303.shp to shp...\n",
      "Rasterizing NFHL_51_20230303.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_15_20221205.shp...\n",
      "Saving NFHL_15_20221205.shp to shp...\n",
      "Rasterizing NFHL_15_20221205.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_28_20220815.shp...\n",
      "Saving NFHL_28_20220815.shp to shp...\n",
      "Rasterizing NFHL_28_20220815.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_44_20221023.shp...\n",
      "Saving NFHL_44_20221023.shp to shp...\n",
      "Rasterizing NFHL_44_20221023.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Processing NFHL_47_20230125.shp...\n",
      "Saving NFHL_47_20230125.shp to shp...\n",
      "Rasterizing NFHL_47_20230125.shp...\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Preprocessing complete\n",
      "CPU times: user 23min 26s, sys: 1min 2s, total: 24min 29s\n",
      "Wall time: 25min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# preprocess shapefile\n",
    "print(\"Preprocessing shapefile data...\")\n",
    "\n",
    "combined_array = combine_state_inland_flood_risk_data()\n",
    "\n",
    "print('Preprocessing complete')\n",
    "\n",
    "# swap the 1 and 0 values in the combined raster\n",
    "combined_array = np.where(combined_array == 1, 0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2d283",
   "metadata": {},
   "source": [
    "#### coastal flood risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "855e59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct local directory paths\n",
    "output_tif_file_name = \"gridcerf_fema_1pct_or_greater_coastal_flood_risk.tif\"\n",
    "output_raster = os.path.join(technology_specific_dir, output_tif_file_name)\n",
    "\n",
    "# generate raster for included area\n",
    "vector_to_raster(template_raster=template_raster, \n",
    "                 land_mask_raster=template_raster,\n",
    "                 gdf=gdf, \n",
    "                 value_field=\"value\",\n",
    "                 output_raster=output_raster, \n",
    "                include=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced098b",
   "metadata": {},
   "source": [
    "#### 100-year flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa904b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raster file to technology_specific folder\n",
    "output_tif_file_name = \"gridcerf_fema_1pct_or_greater_inland_flood_risk.tif\"\n",
    "output_raster_path = os.path.join(technology_specific_dir, output_tif_file_name)\n",
    "\n",
    "# read in template for metadata\n",
    "template = rasterio.open(template_raster)\n",
    "metadata = template.meta.copy()\n",
    "\n",
    "# write file\n",
    "with rasterio.open(output_raster_path, 'w', **metadata) as dest:\n",
    "    \n",
    "    dest.write(combined_array, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
